{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OObv3gMQeHQk"
   },
   "source": [
    "Training a Multilayer Perceptron (MLP) model to identify hand-written digits\n",
    "\n",
    "Adapted from: \n",
    "\n",
    "https://github.com/FluxML/model-zoo/tree/master/vision/mlp_mnist​\n",
    "\n",
    "https://github.com/FluxML/model-zoo/tree/master?tab=readme-ov-file#examples-in-the-model-zoo​\n",
    "\n",
    "https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yF4vwt4PbYWb"
   },
   "source": [
    "Check Kernel status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 756927,
     "status": "ok",
     "timestamp": 1733409861022,
     "user": {
      "displayName": "quser northwestern",
      "userId": "16594126223941717026"
     },
     "user_tz": 360
    },
    "id": "zlHKaDfvOx6G",
    "outputId": "521b3a06-cb5b-4529-df6a-1ca3e7848d6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.11.4\n",
      "Commit 8561cc3d68d (2025-03-10 11:36 UTC)\n",
      "Build Info:\n",
      "  Official https://julialang.org/ release\n",
      "Platform Info:\n",
      "  OS: Linux (x86_64-linux-gnu)\n",
      "  CPU: 64 × Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz\n",
      "  WORD_SIZE: 64\n",
      "  LLVM: libLLVM-16.0.6 (ORCJIT, icelake-server)\n",
      "Threads: 1 default, 0 interactive, 1 GC (on 64 virtual cores)\n",
      "Environment:\n",
      "  LD_LIBRARY_PATH = /.singularity.d/libs\n",
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `/projects/e33102/giannini_projects/my_ml_ds_project/Project.toml`\n",
      "  \u001b[90m[336ed68f] \u001b[39mCSV v0.10.15\n",
      "  \u001b[90m[8f4d0f93] \u001b[39mConda v1.10.3\n",
      "  \u001b[90m[a93c6f00] \u001b[39mDataFrames v1.8.1\n",
      "  \u001b[90m[587475ba] \u001b[39mFlux v0.16.5\n",
      "  \u001b[90m[7073ff75] \u001b[39mIJulia v1.33.0\n",
      "  \u001b[90m[a09fc81d] \u001b[39mImageCore v0.10.5\n",
      "  \u001b[90m[916415d5] \u001b[39mImages v0.26.2\n",
      "  \u001b[90m[eb30cadb] \u001b[39mMLDatasets v0.7.18\n",
      "  \u001b[90m[91a5bcdd] \u001b[39mPlots v1.41.2\n",
      "  \u001b[90m[10745b16] \u001b[39mStatistics v1.11.1\n",
      "  \u001b[90m[f3b207a7] \u001b[39mStatsPlots v0.15.8\n"
     ]
    }
   ],
   "source": [
    "versioninfo()\n",
    "\n",
    "using Pkg\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9HkjqfGbkNP"
   },
   "source": [
    "Import the necessary packages (this should be relatively quick if your Kernel is setup correctly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33708,
     "status": "ok",
     "timestamp": 1733411837407,
     "user": {
      "displayName": "quser northwestern",
      "userId": "16594126223941717026"
     },
     "user_tz": 360
    },
    "id": "viE7emgVScLJ",
    "outputId": "b2690753-7ea4-421c-dcb2-4091ed45c08c"
   },
   "outputs": [],
   "source": [
    "using Pkg, Flux, MLDatasets, Statistics, ImageCore, Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9CTayz7vcBze"
   },
   "source": [
    "Define the model! It consists of the inputs, one hidden layer, and the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5477,
     "status": "ok",
     "timestamp": 1733411999462,
     "user": {
      "displayName": "quser northwestern",
      "userId": "16594126223941717026"
     },
     "user_tz": 360
    },
    "id": "sttQjPuBZRFl",
    "outputId": "0234f7ce-cc8d-4359-aa71-2e8d797dbe6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One random `image`\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1 = Float32[0.06042187, 0.06372577, 0.056332376, 0.17219526, 0.16186148, 0.04936383, 0.10934783, 0.05137698, 0.23348157, 0.04189297]\n",
      "sum(p1) ≈ 1 = true\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Three random `images`\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p3 = Float32[0.062264618 0.05782809 0.06331551; 0.078603655 0.068102054 0.062567554; 0.06450193 0.05240976 0.05963539; 0.16862895 0.16002503 0.17837179; 0.18733196 0.20277967 0.17811894; 0.041343037 0.04077368 0.038733527; 0.118857965 0.09692651 0.10960676; 0.057611495 0.05787921 0.05279039; 0.15911986 0.21217598 0.19998616; 0.06173657 0.05110003 0.056873932]\n",
      "sum(p3; dims = 1) = Float32[1.0 1.0 0.99999994]\n"
     ]
    }
   ],
   "source": [
    "# Our model is very simple: Its one \"hidden layer\" has 32 \"neurons\" each connected to every input pixel.\n",
    "# Each has a sigmoid nonlinearity, and is connected to every \"neuron\" in the output layer.\n",
    "# Finally, softmax produces probabilities, i.e. positive numbers which add up to 1:\n",
    "\n",
    "## Notice the sizes of things: square images going into 32 neurons\n",
    "## then to the output layer, which is the probability that an input\n",
    "## maps to a certain digit\n",
    "model = Chain(Dense(28^2 => 32, sigmoid), Dense(32 => 10), softmax)\n",
    "\n",
    "p1 = model(rand(Float32, 28^2))  # run model on random data shaped like an image\n",
    "\n",
    "display(\"One random `image`\")\n",
    "@show p1\n",
    "@show sum(p1) ≈1;\n",
    "\n",
    "p3 = model(rand(Float32, 28^2, 3))  # ...or on a batch of 3 fake, random \"images\"\n",
    "\n",
    "display(\"Three random `images`\")\n",
    "@show p3\n",
    "@show sum(p3; dims=1);  # all approx 1. Last dim is batch dim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Odf0HnCAd12F"
   },
   "source": [
    "Load in the MNIST data - it will ask for verification that you want to download the dataset\n",
    "\n",
    "Note: one-hot and one-cold encoding are used below - more information here : https://fluxml.ai/Flux.jl/previews/PR1612/data/onehot/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2200,
     "status": "ok",
     "timestamp": 1733413452922,
     "user": {
      "displayName": "quser northwestern",
      "userId": "16594126223941717026"
     },
     "user_tz": 360
    },
    "id": "T2YqnvocaBX-",
    "outputId": "d3dc7a54-e1ee-4fda-9213-819274755498"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(y1) = (10, 64)\n",
      "Flux.crossentropy(model(x1), y1) = 2.4358923f0\n"
     ]
    }
   ],
   "source": [
    "#===== DATA =====#\n",
    "\n",
    "# Calling MLDatasets.MNIST() will dowload the dataset if necessary,\n",
    "# and return a struct containing it.\n",
    "# It takes a few seconds to read from disk each time, so do this once:\n",
    "\n",
    "train_data = MLDatasets.MNIST()  # i.e. split=:train\n",
    "test_data = MLDatasets.MNIST(split=:test)\n",
    "\n",
    "# train_data.features is a 28×28×60000 Array{Float32, 3} of the images.\n",
    "# We need a 2D array for our model. Let's combine the reshape needed with\n",
    "# other pre-processing, in a function:\n",
    "\n",
    "function simple_loader(data::MNIST; batchsize::Int=64)\n",
    "    x2dim = reshape(data.features, 28^2, :)\n",
    "    yhot = Flux.onehotbatch(data.targets, 0:9)\n",
    "    Flux.DataLoader((x2dim, yhot); batchsize, shuffle=true)\n",
    "end\n",
    "\n",
    "# train_data.targets is a 60000-element Vector{Int}, of labels from 0 to 9.\n",
    "# Flux.onehotbatch([0,1,9], 0:9) makes a matrix of 0 and 1.\n",
    "\n",
    "# Load the training data\n",
    "simple_loader(train_data)  # returns a DataLoader, with first element a tuple like this:\n",
    "\n",
    "x1, y1 = first(simple_loader(train_data)); # (784×64 Matrix{Float32}, 10×64 OneHotMatrix)\n",
    "\n",
    "model(x1)  # x1 is the right shape for our model\n",
    "\n",
    "@show size(y1)  # y1 is the same shape as the model output.\n",
    "\n",
    "## Calculating the loss function on the untrained model\n",
    "@show Flux.crossentropy(model(x1), y1);  # This will be our loss function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEnAbPBIfl3a"
   },
   "source": [
    "What does the (training) data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150
    },
    "executionInfo": {
     "elapsed": 180,
     "status": "ok",
     "timestamp": 1733415503387,
     "user": {
      "displayName": "quser northwestern",
      "userId": "16594126223941717026"
     },
     "user_tz": 360
    },
    "id": "_ohZgacufmS-",
    "outputId": "cbb519a7-218d-4e95-cb05-d64acbcc8e5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 64)\n",
      "Bool[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAj9JREFUaAW9wT+IFQQAB+Dv4IdBhIFDm1DUdqtRQ5rEgUWDRBcRtNQS3UVDHgRJ4AXNQoNDYFOFkkG0eENDGC0ebpkRL3C5iAQvBa+y8BreIPfP917K7/uiLMqiLMqiLMqiLMqiLMqiLMqiLMqiLMpiG4/gftzAZfdWlEVZlMU2PsEBXMOn+AgD90aURVmUxTYW8CV2Yx6vYc1GU1jHMj7EMv41WpRFWZTFNi7gYTyEE9iLfTYaYAUzeA4LOG60KIuyKIs7+B2zuA+P2ug3XMWT+B5HcdxoURZlURZj+Bs/2t4fmMIe44myKIuyuEtHsY5fjCfKoizK4n/Yg+AdvIJ/sGg8URZlURYT2IVjmMODuGXoC3xmPFEWZVEWE3gT7xpad9tjOIBzRouyKIuymMDHeAaHsIqTeB5P4Ft8h1M4jwGu2SrKoizKYgJ/4jAex69YwQeYxQnsx1OGvsFLuG6jKIuyKItNfsILuGRny267ic9xFm9jGgcxg69x0EZRFmVRFps8gCU8i0vGt4pFQ8fwPvbbKsqiLMpik0NYwlnMYGBy03YWZVEWZbHJRezFGfyMU3gLV402jSN4EWt41VZRFmVRFjtYwCpexz6s4DwuYIDrGBiaxTyexjou4hi+slWURVmUxQ4uYx7vYQ6HcQRT+Au3sGZoN3bhCpYwhxu2F2VRFmVxBzdxBYtYxMt4w9A5/GCjM0aLsiiLspjAaZx2d6IsyqIsyqIsyqIsyqIsyqIsyqIsyqIsyqIsyqLsP3KGZukUIvlxAAAAAElFTkSuQmCC",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAj9JREFUaAW9wT+IFQQAB+Dv4IdBhIFDm1DUdqtRQ5rEgUWDRBcRtNQS3UVDHgRJ4AXNQoNDYFOFkkG0eENDGC0ebpkRL3C5iAQvBa+y8BreIPfP917K7/uiLMqiLMqiLMqiLMqiLMqiLMqiLMqiLMpiG4/gftzAZfdWlEVZlMU2PsEBXMOn+AgD90aURVmUxTYW8CV2Yx6vYc1GU1jHMj7EMv41WpRFWZTFNi7gYTyEE9iLfTYaYAUzeA4LOG60KIuyKIs7+B2zuA+P2ug3XMWT+B5HcdxoURZlURZj+Bs/2t4fmMIe44myKIuyuEtHsY5fjCfKoizK4n/Yg+AdvIJ/sGg8URZlURYT2IVjmMODuGXoC3xmPFEWZVEWE3gT7xpad9tjOIBzRouyKIuymMDHeAaHsIqTeB5P4Ft8h1M4jwGu2SrKoizKYgJ/4jAex69YwQeYxQnsx1OGvsFLuG6jKIuyKItNfsILuGRny267ic9xFm9jGgcxg69x0EZRFmVRFps8gCU8i0vGt4pFQ8fwPvbbKsqiLMpik0NYwlnMYGBy03YWZVEWZbHJRezFGfyMU3gLV402jSN4EWt41VZRFmVRFjtYwCpexz6s4DwuYIDrGBiaxTyexjou4hi+slWURVmUxQ4uYx7vYQ6HcQRT+Au3sGZoN3bhCpYwhxu2F2VRFmVxBzdxBYtYxMt4w9A5/GCjM0aLsiiLspjAaZx2d6IsyqIsyqIsyqIsyqIsyqIsyqIsyqIsyqIsyqLsP3KGZukUIvlxAAAAAElFTkSuQmCC\">"
      ],
      "text/plain": [
       "28×28 Matrix{Gray{Float32}}:\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0       …  0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.129412     0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.74902   …  0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.2          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0       …  0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " ⋮                             ⋮         ⋱                 ⋮         \n",
       " 0.0  0.0  0.0  0.0  0.847059  0.160784     0.752941  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.894118  0.882353     0.992157  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.168627  0.890196     0.992157  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.313726  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0       …  0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0       …  0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(size(x1))\n",
    "\n",
    "show_ind = 5\n",
    "\n",
    "println(y1[:,show_ind])\n",
    "\n",
    "reshape(x1[:,show_ind], 28, 28) .|> Gray |> transpose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uwA-idOeV0V"
   },
   "source": [
    "Define a function to determine the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 798,
     "status": "ok",
     "timestamp": 1733415528057,
     "user": {
      "displayName": "quser northwestern",
      "userId": "16594126223941717026"
     },
     "user_tz": 360
    },
    "id": "Kxols-WzaWVE",
    "outputId": "ac0ea3c4-7f3a-4ab4-c1b8-de3c7708796d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_accuracy(model) = 10.45\n"
     ]
    }
   ],
   "source": [
    "#===== ACCURACY =====#\n",
    "\n",
    "# We're going to log accuracy and loss during training. There's no advantage to\n",
    "# calculating these on minibatches, since MNIST is small enough to do it at once.\n",
    "\n",
    "function simple_accuracy(model, data::MNIST=test_data)\n",
    "    (x, y) = only(simple_loader(data; batchsize=length(data)))  # make one big batch\n",
    "    y_hat = model(x)\n",
    "    iscorrect = Flux.onecold(y_hat) .== Flux.onecold(y)  # BitVector\n",
    "    acc = round(100 * mean(iscorrect); digits=2)\n",
    "end\n",
    "\n",
    "@show simple_accuracy(model);  # accuracy about 10%, on training data, before training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2APT1AYCepMu"
   },
   "source": [
    "Train the model on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52067,
     "status": "ok",
     "timestamp": 1733412170050,
     "user": {
      "displayName": "quser northwestern",
      "userId": "16594126223941717026"
     },
     "user_tz": 360
    },
    "id": "RaJldb8uabCh",
    "outputId": "36ca000f-4f99-4d55-9b44-a0b4354e8e02"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mAfter epoch = 1\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  loss = 1.769801369868219\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  train_acc = 77.93\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m  test_acc = 79.04\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mAfter epoch = 3\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  loss = 0.8311573090031743\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  train_acc = 86.1\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m  test_acc = 86.95\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mAfter epoch = 5\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  loss = 0.5607165765250102\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  train_acc = 88.68\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m  test_acc = 89.11\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mAfter epoch = 7\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  loss = 0.44117479829583317\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  train_acc = 89.89\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m  test_acc = 90.37\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mAfter epoch = 9\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  loss = 0.3758481174008921\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  train_acc = 90.88\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m  test_acc = 91.05\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mAfter epoch = 11\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  loss = 0.3344664351316169\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  train_acc = 91.57\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m  test_acc = 91.69\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mAfter epoch = 13\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  loss = 0.30574356886791065\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  train_acc = 92.02\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m  test_acc = 92.13\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mAfter epoch = 15\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  loss = 0.2836741111241281\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  train_acc = 92.5\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m  test_acc = 92.55\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mAfter epoch = 17\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  loss = 0.26557572692399845\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  train_acc = 92.93\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m  test_acc = 92.86\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mAfter epoch = 19\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  loss = 0.2514247032231651\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  train_acc = 93.26\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m  test_acc = 93.03\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mAfter epoch = 21\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  loss = 0.23839688848238438\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  train_acc = 93.6\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m  test_acc = 93.21\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mAfter epoch = 23\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  loss = 0.22771768999518827\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  train_acc = 93.88\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m  test_acc = 93.43\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mAfter epoch = 25\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  loss = 0.21835393470246345\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  train_acc = 94.12\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m  test_acc = 93.66\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mAfter epoch = 27\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  loss = 0.20975919577176683\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  train_acc = 94.34\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m  test_acc = 93.89\n",
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mAfter epoch = 29\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  loss = 0.20213438710197806\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  train_acc = 94.53\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m  test_acc = 94.01\n"
     ]
    }
   ],
   "source": [
    "#===== TRAINING =====#\n",
    "\n",
    "# Make a dataloader using the desired batchsize:\n",
    "\n",
    "train_loader = simple_loader(train_data, batchsize = 256)\n",
    "\n",
    "# Initialise storage needed for the Adam optimiser, with our chosen learning rate:\n",
    "\n",
    "opt_state = Flux.setup(Adam(3e-4), model);\n",
    "\n",
    "# Then train for 30 epochs, printing out details as we go:\n",
    "\n",
    "for epoch in 1:30\n",
    "    loss = 0.0\n",
    "    for (x, y) in train_loader\n",
    "        # Compute the loss and the gradients:\n",
    "        l, gs = Flux.withgradient(m -> Flux.crossentropy(m(x), y), model)\n",
    "        # Update the model parameters (and the Adam momenta):\n",
    "        Flux.update!(opt_state, model, gs[1])\n",
    "        # Accumulate the mean loss, just for logging:\n",
    "        loss += l / length(train_loader)\n",
    "    end\n",
    "\n",
    "    if mod(epoch, 2) == 1\n",
    "        # Report on train and test, only every 2nd epoch:\n",
    "        train_acc = simple_accuracy(model, train_data)\n",
    "        test_acc = simple_accuracy(model, test_data)\n",
    "        @info \"After epoch = $epoch\" loss train_acc test_acc\n",
    "    end\n",
    "end\n",
    "\n",
    "# This should get to about 94% accuracy.\n",
    "# To do better, try using Dense(784 => 64, relu) instead.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0-VZcJ0ex4k"
   },
   "source": [
    "Inspect the results of the training (for one number)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1733415593228,
     "user": {
      "displayName": "quser northwestern",
      "userId": "16594126223941717026"
     },
     "user_tz": 360
    },
    "id": "ri0COI05aec4"
   },
   "outputs": [],
   "source": [
    "#===== INSPECTION =====#\n",
    "\n",
    "using ImageCore #, ImageInTerminal\n",
    "\n",
    "## Load test data\n",
    "xtest, ytest = only(simple_loader(test_data, batchsize=length(test_data)));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "executionInfo": {
     "elapsed": 170,
     "status": "ok",
     "timestamp": 1733415674151,
     "user": {
      "displayName": "quser northwestern",
      "userId": "16594126223941717026"
     },
     "user_tz": 360
    },
    "id": "kaZcVF7if5s8",
    "outputId": "9020beb3-ebea-401a-e904-24565e1c98d3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAg9JREFUaAW9wTGIlgUABuDH6zWDgoIrCuOCoJoLGoKDCArKwSlq8QpaDgRrECEcJBqjoMkhaHVod3CLGtJJCsKh2iLJ6CB0ye6ohm/4+LHv///P4H2eKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuymOkePIgdHMUp3I+beBVXLBdlURZlsaZD2MXLeN2iv/EA3sYVy0VZlEVZrOFRnMDHRn/gRzyGLYMbVouyKIuyWMMZnDa6inO4hC1cwDZexMP43bQoi7IoixWO4V2DP/E5zuGmwc+4hm28hC/wJvb8tyiLsiiLJU7jLA5jH0/jujv9ZnQvbpkWZVEWZTHheXyEDYM3cN2dtnHG6Db+Mi3KoizKYsIGNoy+t2gTJ/E+jhgc4JLloizKoiwmbFr0Ay4YvYZHLPoKn1guyqIsymLCQxZt4C3TvsU7VouyKIuymHAR5/GEwVP4yaItPIt9nMIvVouyKIuymHAL7xltYs+irw0O4zlctlqURVmUxZr2jB7HWbxg8A2+s54oi7Ioi7vwJE4a7OMV3LaeKIuyKIv/6RoOrC/KoizKYqb7cMLoKA5ZX5RFWZTFDEfwKXYNfsVxHFhflEVZlMUMx7BrtIOr5omyKIuymOEiPsQHBsfxpXmiLMqiLGY4wGfYwT+4bL4oi7Ioi5lu4Bl3L8qiLMqiLMqiLMr+Ba83SLaVfoObAAAAAElFTkSuQmCC",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAg9JREFUaAW9wTGIlgUABuDH6zWDgoIrCuOCoJoLGoKDCArKwSlq8QpaDgRrECEcJBqjoMkhaHVod3CLGtJJCsKh2iLJ6CB0ye6ohm/4+LHv///P4H2eKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuymOkePIgdHMUp3I+beBVXLBdlURZlsaZD2MXLeN2iv/EA3sYVy0VZlEVZrOFRnMDHRn/gRzyGLYMbVouyKIuyWMMZnDa6inO4hC1cwDZexMP43bQoi7IoixWO4V2DP/E5zuGmwc+4hm28hC/wJvb8tyiLsiiLJU7jLA5jH0/jujv9ZnQvbpkWZVEWZTHheXyEDYM3cN2dtnHG6Db+Mi3KoizKYsIGNoy+t2gTJ/E+jhgc4JLloizKoiwmbFr0Ay4YvYZHLPoKn1guyqIsymLCQxZt4C3TvsU7VouyKIuymHAR5/GEwVP4yaItPIt9nMIvVouyKIuymHAL7xltYs+irw0O4zlctlqURVmUxZr2jB7HWbxg8A2+s54oi7Ioi7vwJE4a7OMV3LaeKIuyKIv/6RoOrC/KoizKYqb7cMLoKA5ZX5RFWZTFDEfwKXYNfsVxHFhflEVZlMUMx7BrtIOr5omyKIuymOEiPsQHBsfxpXmiLMqiLGY4wGfYwT+4bL4oi7Ioi5lu4Bl3L8qiLMqiLMqiLMr+Ba83SLaVfoObAAAAAElFTkSuQmCC\">"
      ],
      "text/plain": [
       "28×28 Matrix{Gray{Float32}}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0        …  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0           0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0           0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0           0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0           0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0        …  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0           0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0           0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0           0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0           0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0        …  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0           0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.203922      0.0  0.0  0.0  0.0  0.0  0.0\n",
       " ⋮                        ⋮               ⋱                 ⋮         \n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0509804     0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0           0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0           0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0           0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0        …  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0           0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0           0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0           0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0           0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0        …  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0           0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0           0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are many ways to look at images, you won't need ImageInTerminal if working in a notebook.\n",
    "# ImageCore.Gray is a special type, which interprets numbers between 0.0 and 1.0 as shades:\n",
    "\n",
    "show_ind = 76\n",
    "\n",
    "reshape(xtest[:,show_ind], 28, 28) .|> Gray |> transpose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "executionInfo": {
     "elapsed": 706,
     "status": "ok",
     "timestamp": 1733415670353,
     "user": {
      "displayName": "quser northwestern",
      "userId": "16594126223941717026"
     },
     "user_tz": 360
    },
    "id": "y4nuBO9yahMm",
    "outputId": "dafbab5d-0324-46f3-a7be-1c9711cebc0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Flux.onecold(ytest, 0:9))[show_ind] = 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10-element Vector{Pair{Int64, Float32}}:\n",
       " 0 => 2.4962404f-5\n",
       " 1 => 1.5868129f-5\n",
       " 2 => 2.8185075f-5\n",
       " 3 => 3.9556096f-5\n",
       " 4 => 0.0061218557\n",
       " 5 => 0.0002150272\n",
       " 6 => 2.9786357f-5\n",
       " 7 => 0.002095968\n",
       " 8 => 0.00067733845\n",
       " 9 => 0.9907514"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@show Flux.onecold(ytest, 0:9)[show_ind];  # true label, should match!\n",
    "\n",
    "# Now we can compare the model's probabilities, for the same input.\n",
    "# This should be highest at the same number:\n",
    "\n",
    "p10 = (0:9) .=> model(xtest[:, show_ind]);\n",
    "display(p10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 175,
     "status": "ok",
     "timestamp": 1733415705743,
     "user": {
      "displayName": "quser northwestern",
      "userId": "16594126223941717026"
     },
     "user_tz": 360
    },
    "id": "_iwx39-7anXY",
    "outputId": "baa61588-2d46-468e-80f7-90acc371a1d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of test dataset : (784, 10000)\n",
      "size of output predictions : (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "using ImageCore\n",
    "\n",
    "# Get test data\n",
    "xtest, ytest = only(simple_loader(test_data, batchsize=length(test_data)))\n",
    "println(\"size of test dataset : \", size(xtest))\n",
    "\n",
    "# Compute model predictions for the entire test set\n",
    "predictions = model(xtest)\n",
    "println(\"size of output predictions : \", size(predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYEE_9ZOguN8"
   },
   "source": [
    "Exercise!\n",
    "\n",
    "For this set of test data inputs and prediction outputs, find the sample that has the least confident overall classification. Print a table of the predictions for that sample and plot the image.\n",
    "\n",
    "Hints:\n",
    "\n",
    "1) Find the maximum predicted probabilities for each sample\n",
    "\n",
    "2) Identify the index of the sample with the least confident classification\n",
    "\n",
    "3) Extract/slice the least confident image, its true label, and the set of predictions for it\n",
    "\n",
    "4) Display the least confident image\n",
    "\n",
    "5) Print the list of predictions and the true label\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A possible answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAjxJREFUaAW9wUGo3wMAB/DP3762g0xbPQyjUIsbJ9ZyGCOl5LITFxYHiR12mAtWysErLZHeDVfRyEHJZTUHRWoOypqTg14vnmUvy3P4Hf69/Pbe+z/z/XyiLMqiLMqiLMqiLMqiLMqiLMrif3I9bjL4zlSURVmUxRW0FwdxCAdwKz7F46aiLMqiLP6Do7gFd+IhbMMOrGIVJ3DCWlEWZVEWW7Qbz+N2a60avIFX/VuURVmUxRYt4zMs4THsMbgRV+GscVEWZVEWW/QXXjJ4DfvwIOaxA3PGRVmURVnMYILrTP2BS3gSR/AALmIeHxoXZVEWZTGDF/CWqS+whIOYwyK+wUksGhdlURZlMYO91nrY1G94GQvWF2VRFmUxg0tYwi6cxwS3GZzCgo1FWZRFWczgOBawG+cN3sZh3GVzoizKoixmdA7nTH2Mw9iHu/GD9UVZlEVZjHgUT+Argz/xiXF/G0wwsbEoi7IoixHHcQBHDFbxJt7FRWzD1fgFTxucNbgWyy4vyqIsymLEBWtNcAzHsITtuAZncLPBTtyLZSy7vCiLsiiLEXMGp/EzHsFObMcuU/cbrOA9fGBjURZlURYjXsdHuAen8BT2Yw8O4VlTP+J9nLQ5URZlURYjPsfXuA+v4DlTN5j6Fi/itM2LsiiLshixgv04inncYep3nMGveAaLZhNlURZlsY538KW1LuAnWxdlURZlsY4VfO/KirIoi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7J/AJHmVqDh6gQHAAAAAElFTkSuQmCC",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAjxJREFUaAW9wUGo3wMAB/DP3762g0xbPQyjUIsbJ9ZyGCOl5LITFxYHiR12mAtWysErLZHeDVfRyEHJZTUHRWoOypqTg14vnmUvy3P4Hf69/Pbe+z/z/XyiLMqiLMqiLMqiLMqiLMqiLMrif3I9bjL4zlSURVmUxRW0FwdxCAdwKz7F46aiLMqiLP6Do7gFd+IhbMMOrGIVJ3DCWlEWZVEWW7Qbz+N2a60avIFX/VuURVmUxRYt4zMs4THsMbgRV+GscVEWZVEWW/QXXjJ4DfvwIOaxA3PGRVmURVnMYILrTP2BS3gSR/AALmIeHxoXZVEWZTGDF/CWqS+whIOYwyK+wUksGhdlURZlMYO91nrY1G94GQvWF2VRFmUxg0tYwi6cxwS3GZzCgo1FWZRFWczgOBawG+cN3sZh3GVzoizKoixmdA7nTH2Mw9iHu/GD9UVZlEVZjHgUT+Argz/xiXF/G0wwsbEoi7IoixHHcQBHDFbxJt7FRWzD1fgFTxucNbgWyy4vyqIsymLEBWtNcAzHsITtuAZncLPBTtyLZSy7vCiLsiiLEXMGp/EzHsFObMcuU/cbrOA9fGBjURZlURYjXsdHuAen8BT2Yw8O4VlTP+J9nLQ5URZlURYjPsfXuA+v4DlTN5j6Fi/itM2LsiiLshixgv04inncYep3nMGveAaLZhNlURZlsY538KW1LuAnWxdlURZlsY4VfO/KirIoi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7J/AJHmVqDh6gQHAAAAAElFTkSuQmCC\">"
      ],
      "text/plain": [
       "28×28 Matrix{Gray{Float32}}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0       …  0.0       0.0         0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0          0.0       0.0         0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0          0.0       0.0         0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0          0.188235  0.188235    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0          0.996078  0.694118    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0       …  0.501961  0.00784314  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0          0.0       0.0         0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0          0.0       0.0         0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0          0.0       0.0         0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0          0.0       0.0         0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0       …  0.0       0.0         0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0          0.0       0.0         0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0          0.0       0.0         0.0  0.0  0.0\n",
       " ⋮                        ⋮         ⋱                        ⋮         \n",
       " 0.0  0.0  0.0  0.0  0.0  0.760784     0.0       0.0         0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.717647     0.0       0.0         0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.8          0.0       0.0         0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.317647     0.0       0.0         0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.027451  …  0.0       0.0         0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0          0.0       0.0         0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0          0.0       0.0         0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0          0.0       0.0         0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0          0.0       0.0         0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0       …  0.0       0.0         0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0          0.0       0.0         0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0          0.0       0.0         0.0  0.0  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for least confidently classified image:\n",
      "Pair{Int64, Float32}[0 => 0.057275046, 1 => 0.01284763, 2 => 0.21710232, 3 => 0.009467331, 4 => 0.2132064, 5 => 0.16356936, 6 => 0.23095408, 7 => 0.011325279, 8 => 0.082771935, 9 => 0.0014806631]\n",
      "True Label: 3\n",
      "Predicted Label: 6\n",
      "Confidence: 0.23095408\n"
     ]
    }
   ],
   "source": [
    "# Find maximum probabilities for each test sample\n",
    "max_probs = maximum(predictions, dims=1) |> vec  # Flatten to a vector\n",
    "\n",
    "# Identify the index of the least confident classification\n",
    "least_confident_index = argmin(max_probs)\n",
    "\n",
    "# Extract the least confident image and its true label\n",
    "least_confident_image = xtest[:, least_confident_index]\n",
    "true_label = Flux.onecold(ytest, 0:9)[least_confident_index]\n",
    "predicted_label = Flux.onecold(predictions[:, least_confident_index], 0:9) \n",
    "confidence = max_probs[least_confident_index]\n",
    "\n",
    "# Display the least confident image\n",
    "img = reshape(least_confident_image, 28, 28) .|> Gray |> transpose\n",
    "display(img)\n",
    "\n",
    "## Predictions\n",
    "println(\"Predictions for least confidently classified image:\")\n",
    "println((0:9) .=> predictions[:, least_confident_index])\n",
    "\n",
    "# Print details\n",
    "println(\"True Label: $true_label\")\n",
    "println(\"Predicted Label: $predicted_label\")\n",
    "println(\"Confidence: $confidence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOZ0kc+osdwTKpx11iLumFn",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Julia 1.11.4 - my_ml_ds_project 1.11",
   "language": "julia",
   "name": "julia-1.11.4---my_ml_ds_project-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
